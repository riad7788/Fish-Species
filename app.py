import streamlit as st
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import requests
from io import BytesIO

# --- ‡ßß. ‡¶á‡¶â‡¶®‡¶ø‡¶ï ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶≤‡ßã‡¶°‡¶æ‡¶∞ (‡¶™‡ßÅ‡¶∞‡¶®‡ßã ‡¶ï‡ßç‡¶Ø‡¶æ‡¶∂ ‡¶°‡¶ø‡¶≤‡¶ø‡¶ü ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø) ---
@st.cache_resource(ttl=1) # ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡ßß ‡¶∏‡ßá‡¶ï‡ßá‡¶®‡ßç‡¶° ‡¶™‡¶∞ ‡¶™‡¶∞ ‡¶ï‡ßç‡¶Ø‡¶æ‡¶∂ ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶¨‡ßá
def load_expert_model_v2():
    device = torch.device("cpu")
    
    # ‡¶®‡¶§‡ßÅ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶†‡¶ø‡¶ï ‡¶≤‡¶ø‡¶ô‡ßç‡¶ï
    CLASSIFIER_URL = "https://huggingface.co/riad300/fish-simclr-encoder/resolve/main/fish_expert_weights.pt"
    ENCODER_URL = "https://huggingface.co/riad300/fish-simclr-encoder/resolve/main/encoder_simclr.pt"
    
    # ‡¶è‡¶®‡¶ï‡ßã‡¶°‡¶æ‡¶∞
    encoder = models.resnet50(weights=None)
    encoder.fc = nn.Identity()
    e_state = torch.hub.load_state_dict_from_url(ENCODER_URL, map_location=device)
    encoder.load_state_dict(e_state)
    
    # ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡¶ø‡¶´‡¶æ‡ßü‡¶æ‡¶∞ (‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡ß®‡ßß‡¶ü‡¶ø ‡¶¶‡ßá‡¶∂‡¶ø ‡¶Æ‡¶æ‡¶õ‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø)
    classifier = nn.Linear(2048, 21)
    
    # ‡¶∏‡¶∞‡¶æ‡¶∏‡¶∞‡¶ø ‡¶¨‡¶æ‡¶á‡¶®‡¶æ‡¶∞‡¶ø ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßá ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ (‡¶Ø‡¶æ‡¶§‡ßá ‡¶ï‡ßã‡¶®‡ßã‡¶≠‡¶æ‡¶¨‡ßá‡¶á ‡¶™‡ßÅ‡¶∞‡¶®‡ßã ‡¶ï‡ßç‡¶Ø‡¶æ‡¶∂ ‡¶®‡¶æ ‡¶•‡¶æ‡¶ï‡ßá)
    response = requests.get(CLASSIFIER_URL)
    c_state = torch.load(BytesIO(response.content), map_location=device)
    
    # ‡¶ï‡ßÄ-‡¶Æ‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç ‡¶´‡¶ø‡¶ï‡ßç‡¶∏
    fixed_state = {k.replace('fc.', ''): v for k, v in c_state.items()}
    classifier.load_state_dict(fixed_state)
    
    encoder.eval()
    classifier.eval()
    return encoder, classifier

# --- ‡ß®. ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™ ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡¶´‡ßá‡¶∏ ---
st.set_page_config(page_title="Fish Expert Pro", layout="centered")
st.title("üêü ‡¶¶‡ßá‡¶∂‡¶ø ‡¶Æ‡¶æ‡¶õ ‡¶∂‡¶®‡¶æ‡¶ï‡ßç‡¶§‡¶ï‡¶æ‡¶∞‡ßÄ (Final Fix)")

# ‡¶ï‡ßç‡¶Ø‡¶æ‡¶∂ ‡¶ï‡ßç‡¶≤‡¶ø‡ßü‡¶æ‡¶∞ ‡¶¨‡¶æ‡¶ü‡¶® (‡¶∏‡¶∞‡¶æ‡¶∏‡¶∞‡¶ø ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡¶´‡ßá‡¶∏‡ßá)
if st.button('‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™ ‡¶Ø‡¶¶‡¶ø ‡¶≠‡ßÅ‡¶≤ ‡¶∞‡ßá‡¶ú‡¶æ‡¶≤‡ßç‡¶ü ‡¶¶‡ßá‡ßü ‡¶§‡¶¨‡ßá ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶® (Force Refresh)'):
    st.cache_resource.clear()
    st.rerun()

encoder, classifier = load_expert_model_v2()

# ‡ß®‡ßß‡¶ü‡¶ø ‡¶Æ‡¶æ‡¶õ‡ßá‡¶∞ ‡¶∏‡¶†‡¶ø‡¶ï ‡¶®‡¶æ‡¶Æ‡ßá‡¶∞ ‡¶§‡¶æ‡¶≤‡¶ø‡¶ï‡¶æ
CLASSES = [
    "Baim (‡¶¨‡¶æ‡¶á‡¶®)", "Bata (‡¶¨‡¶æ‡¶ü‡¶æ)", "Batasio/Tengra (‡¶ü‡ßá‡¶Ç‡¶∞‡¶æ)", "Chitul (‡¶ö‡¶ø‡¶§‡¶≤)", 
    "Croaker/Poya (‡¶™‡ßã‡¶Ø‡¶º‡¶æ)", "Hilsha (‡¶á‡¶≤‡¶ø‡¶∂)", "Kajoli (‡¶ï‡¶æ‡¶ú‡¶≤‡ßÄ)", "Meni (‡¶Æ‡ßá‡¶®‡¶ø)", 
    "Pabda (‡¶™‡¶æ‡¶¨‡¶¶‡¶æ)", "Poli (‡¶´‡¶≤‡¶ø)", "Puti (‡¶™‡ßÅ‡¶Å‡¶ü‡¶ø)", "Rita (‡¶∞‡¶ø‡¶ü‡¶æ)", 
    "Rui (‡¶∞‡ßÅ‡¶á)", "Rupchanda (‡¶∞‡ßÇ‡¶™‡¶ö‡¶æ‡¶Å‡¶¶‡¶æ)", "Silver Carp (‡¶∏‡¶ø‡¶≤‡¶≠‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶∞‡ßç‡¶™)", 
    "Telapiya (‡¶§‡ßá‡¶≤‡¶æ‡¶™‡¶ø‡ßü‡¶æ)", "Carp (‡¶ï‡¶æ‡¶∞‡ßç‡¶™)", "Koi (‡¶ï‡ßà)", 
    "Kaikka (‡¶ï‡¶æ‡¶ákka)", "Koral (‡¶ï‡ßã‡¶∞‡¶æ‡¶≤)", "Shrimp (‡¶ö‡¶ø‡¶Ç‡ßú‡¶ø)"
]

file = st.file_uploader("‡¶Æ‡¶æ‡¶õ‡ßá‡¶∞ ‡¶õ‡¶¨‡¶ø ‡¶¶‡¶ø‡¶®", type=["jpg", "png", "jpeg"])

if file:
    img = Image.open(file).convert("RGB")
    st.image(img, use_container_width=True)
    
    tf = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    with torch.no_grad():
        feats = encoder(tf(img).unsqueeze(0))
        out = classifier(feats)
        prob, idx = torch.max(torch.softmax(out, dim=1), 1)
    
    # ‡¶∞‡ßá‡¶ú‡¶æ‡¶≤‡ßç‡¶ü
    confidence = prob.item() * 100
    st.success(f"### ‡¶∂‡¶®‡¶æ‡¶ï‡ßç‡¶§ ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü‡ßá‡¶õ‡ßá: **{CLASSES[idx.item()]}**")
    st.info(f"‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡ßü‡¶§‡¶æ (Confidence): **{confidence:.2f}%**")
