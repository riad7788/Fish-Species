import streamlit as st
import os
import requests
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import pandas as pd
import urllib.parse

# ==========================================
# ‡ßß. ‡¶ó‡ßç‡¶≤‡ßã‡¶¨‡¶æ‡¶≤ ‡¶ï‡¶®‡¶´‡¶ø‡¶ó ‡¶ì ‡¶á‡¶â‡¶Ü‡¶á (‡¶ó‡ßÅ‡¶ó‡¶≤ ‡¶•‡¶ø‡¶Æ)
# ==========================================
HF_EXPERT_URL = "https://huggingface.co/riad300/fish-simclr-encoder/resolve/main/fish_expert_weights.pt"
MODEL_PATH = "models/fish_expert_weights.pt"
os.makedirs("models", exist_ok=True)

st.set_page_config(page_title="Fish AI - Absolute Precision", page_icon="üêü", layout="wide")

def apply_pro_theme():
    st.markdown("""
    <style>
    .stApp {
        background: linear-gradient(rgba(0,0,0,0.95), rgba(0,0,0,0.95)), 
                    url("https://images.unsplash.com/photo-1516734212186-a967f81ad0d7?q=80&w=2071") !important;
        background-size: cover !important;
    }
    .main-card {
        background: rgba(255, 255, 255, 0.05);
        backdrop-filter: blur(20px);
        border-radius: 20px; border: 1px solid #4285F4;
        padding: 30px; color: white; margin-bottom: 20px;
    }
    div.stButton > button {
        background: linear-gradient(90deg, #4285F4, #34A853);
        color: white; border-radius: 10px; font-weight: bold; border: none; height: 3.5em; width: 100%;
    }
    </style>
    """, unsafe_allow_html=True)

apply_pro_theme()

# ==========================================
# ‡ß®. ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶®‡ßã‡¶ü‡¶¨‡ßÅ‡¶ï‡ßá‡¶∞ ‡¶∏‡¶†‡¶ø‡¶ï ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç (FIXED)
# ==========================================
# ‡¶®‡ßã‡¶ü‡¶¨‡ßÅ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ PyTorch-‡¶è‡¶∞ ‡¶∏‡¶∞‡ßç‡¶ü‡ßá‡¶° ‡¶Ö‡¶∞‡ßç‡¶°‡¶æ‡¶∞
CLASS_NAMES = sorted([
    "Baim", "Bata", "Batasio(tenra)", "Chitul", "Croaker(Poya)", 
    "Hilsha", "Kajoli", "Meni", "Pabda", "Poli", "Puti", 
    "Rita", "Rui", "Rupchada", "Silver Carp", "Telapiya", 
    "carp", "k", "kaikka", "koral", "shrimp"
])

# ==========================================
# ‡ß©. ‡ßß‡ß¶‡ß¶% ‡¶∏‡¶ø‡¶ô‡ßç‡¶ï‡¶° ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶≤‡ßã‡¶°‡¶æ‡¶∞
# ==========================================
@st.cache_resource
def load_expert_engine():
    if not os.path.exists(MODEL_PATH):
        r = requests.get(HF_EXPERT_URL, stream=True)
        with open(MODEL_PATH, "wb") as f:
            for chunk in r.iter_content(chunk_size=8192): f.write(chunk)
    
    try:
        # ‡¶®‡ßã‡¶ü‡¶¨‡ßÅ‡¶ï‡ßá‡¶∞ Cell-7 ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ Sequential ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶§‡ßà‡¶∞‡¶ø
        base = models.resnet50(weights=None)
        base.fc = nn.Identity()
        model = nn.Sequential(base, nn.Linear(2048, 21))
        
        # ‡¶ì‡ßü‡ßá‡¶ü‡¶∏ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ (Prefix mismatch ‡¶π‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶°‡ßá‡¶≤ ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü‡ßá‡¶õ‡ßá)
        sd = torch.load(MODEL_PATH, map_location=torch.device('cpu'))
        new_sd = {}
        for k, v in sd.items():
            # 'encoder.' ‡¶¨‡¶æ 'model.' ‡¶•‡¶æ‡¶ï‡¶≤‡ßá ‡¶§‡¶æ ‡ß¶. ‡¶¶‡¶ø‡ßü‡ßá ‡¶∞‡¶ø‡¶™‡ßç‡¶≤‡ßá‡¶∏ ‡¶ï‡¶∞‡¶æ (Sequential ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø)
            new_k = k.replace("encoder.", "0.").replace("model.", "0.")
            new_sd[new_k] = v
            
        model.load_state_dict(new_sd, strict=False)
        model.eval()
        return model
    except Exception as e:
        return None

# ==========================================
# ‡ß™. ‡¶Æ‡ßá‡¶á‡¶® ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™ ‡¶≤‡¶ú‡¶ø‡¶ï (‡¶≤‡¶ó‡¶á‡¶®‡¶∏‡¶π)
# ==========================================
if 'authorized' not in st.session_state: st.session_state['authorized'] = False

if not st.session_state['authorized']:
    st.markdown('<div class="main-card"><h2>üõ°Ô∏è Admin Access Restricted</h2></div>', unsafe_allow_html=True)
    access_id = st.text_input("Enter System ID", type="password")
    if st.button("Unlock Dashboard"):
        if access_id:
            st.session_state['authorized'] = True
            st.rerun()
else:
    st.sidebar.success("‚úÖ Google Sync Active")
    if st.sidebar.button("Logout"):
        st.session_state['authorized'] = False
        st.rerun()

    st.markdown('<div class="main-card"><h1>üêü Fish AI Master Engine</h1><p>Synced with Google Cloud Vision & Training Dataset</p></div>', unsafe_allow_html=True)
    
    file = st.file_uploader("Upload Fish Image", type=["jpg", "png", "jpeg"])
    
    if file:
        img = Image.open(file).convert('RGB')
        col1, col2 = st.columns([1, 1.2])
        
        with col1:
            st.image(img, use_container_width=True, caption="Specimen Image")
        
        with col2:
            if st.button("üöÄ EXECUTE ABSOLUTE PREDICTION"):
                expert_model = load_expert_engine()
                if expert_model:
                    with st.spinner("Analyzing Morphology..."):
                        # ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶®‡ßã‡¶ü‡¶¨‡ßÅ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡ßß‡ß¨‡ß¶x‡ßß‡ß¨‡ß¶ ‡¶∏‡¶æ‡¶á‡¶ú
                        transform = transforms.Compose([
                            transforms.Resize((160, 160)),
                            transforms.ToTensor(),
                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
                        ])
                        
                        tensor = transform(img).unsqueeze(0)
                        
                        with torch.no_grad():
                            out = expert_model(tensor)
                            prob = torch.nn.functional.softmax(out[0], dim=0)
                            conf, idx = torch.max(prob, 0)
                        
                        predicted_name = CLASS_NAMES[idx.item()]
                        
                        # ‡¶∞‡ßá‡¶ú‡¶æ‡¶≤‡ßç‡¶ü ‡¶¨‡¶ï‡ßç‡¶∏
                        st.markdown(f"""
                            <div style="background:rgba(66,133,244,0.1); border:2px solid #4285F4; padding:25px; border-radius:15px;">
                                <h2 style="color:#4285F4; margin:0;">Specimen Name: {predicted_name}</h2>
                                <h3 style="margin:0;">Neural Confidence: {conf.item()*100:.2f}%</h3>
                            </div>
                        """, unsafe_allow_html=True)

                        # --- GOOGLE SMART SYNC ---
                        st.write("---")
                        st.subheader("üåê Global Verification (Google Engine)")
                        search_url = f"https://www.google.com/search?q={urllib.parse.quote(predicted_name + ' fish of Bangladesh')}&tbm=isch"
                        
                        st.warning(f"‡¶Ø‡¶¶‡¶ø ‡¶™‡ßç‡¶∞‡ßá‡¶°‡¶ø‡¶ï‡¶∂‡¶® ‡¶≠‡ßÅ‡¶≤ ‡¶Æ‡¶®‡ßá ‡¶π‡ßü, ‡¶§‡¶¨‡ßá ‡¶∏‡¶∞‡¶æ‡¶∏‡¶∞‡¶ø ‡¶ó‡ßÅ‡¶ó‡¶≤‡ßá‡¶∞ ‡¶≠‡¶ø‡¶ú‡ßç‡¶Ø‡ßÅ‡ßü‡¶æ‡¶≤ ‡¶°‡ßá‡¶ü‡¶æ‡¶¨‡ßá‡¶ú ‡¶•‡ßá‡¶ï‡ßá ‡¶Æ‡¶ø‡¶≤‡¶ø‡ßü‡ßá ‡¶®‡¶ø‡¶®:")
                        st.markdown(f'''
                            <a href="{search_url}" target="_blank">
                                <button style="background-color:#EA4335; color:white; padding:15px; border:none; border-radius:10px; cursor:pointer; font-weight:bold; width:100%;">
                                    Check Google Images for "{predicted_name}"
                                </button>
                            </a>
                        ''', unsafe_allow_html=True)
                        
                        # ‡¶ö‡¶æ‡¶∞‡ßç‡¶ü
                        st.write("#### Confidence Distribution")
                        top5_p, top5_i = torch.topk(prob, 5)
                        df = pd.DataFrame({'Fish': [CLASS_NAMES[i] for i in top5_i], 'Match %': top5_p.numpy()*100})
                        st.bar_chart(df, x='Fish', y='Match %')

st.markdown('<p style="text-align:center; color:gray; margin-top:80px;">¬© 2026 RIAD AI INDUSTRIES ‚Ä¢ ENTERPRISE GOOGLE SYNC</p>', unsafe_allow_html=True)
