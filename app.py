import streamlit as st
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import os
import requests

# ‡ßß. ‡¶®‡ßã‡¶ü‡¶¨‡ßÅ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶Ü‡¶∞‡ßç‡¶ï‡¶ø‡¶ü‡ßá‡¶ï‡¶ö‡¶æ‡¶∞
class SimCLR_Encoder(nn.Module):
    def __init__(self):
        super().__init__()
        base_model = models.resnet18(weights=None)
        self.features = nn.Sequential(*list(base_model.children())[:-1])

    def forward(self, x):
        x = self.features(x)
        return x.view(x.size(0), -1)

class Classifier(nn.Module):
    def __init__(self, in_dim, num_classes):
        super().__init__()
        self.fc = nn.Linear(in_dim, num_classes)

    def forward(self, x):
        return self.fc(x)

# ‡ß®. ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶´‡ßá‡¶∂‡¶®‡¶æ‡¶≤ ‡¶´‡¶æ‡¶Ç‡¶∂‡¶®
@st.cache_resource
def load_full_system():
    device = torch.device("cpu")
    
    # ‡¶è‡¶®‡¶ï‡ßã‡¶°‡¶æ‡¶∞ ‡¶≤‡¶ø‡¶ô‡ßç‡¶ï (‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶¶‡ßá‡¶ì‡ßü‡¶æ Hugging Face ‡¶≤‡¶ø‡¶ô‡ßç‡¶ï)
    ENCODER_URL = "https://huggingface.co/riad300/fish-simclr-encoder/resolve/main/encoder_simclr.pt"
    
    # ‡¶è‡¶®‡¶ï‡ßã‡¶°‡¶æ‡¶∞ ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶° ‡¶ì ‡¶≤‡ßã‡¶°
    encoder = SimCLR_Encoder()
    encoder_state = torch.hub.load_state_dict_from_url(ENCODER_URL, map_location=device)
    encoder.load_state_dict(encoder_state)
    
    # ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡¶ø‡¶´‡¶æ‡ßü‡¶æ‡¶∞ ‡¶≤‡ßã‡¶° (‡¶è‡¶ü‡¶ø ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ GitHub ‡¶è‡¶∞ models/classifier.pt ‡¶•‡ßá‡¶ï‡ßá ‡¶Ü‡¶∏‡¶¨‡ßá)
    base_dir = os.path.dirname(os.path.abspath(__file__))
    classifier_path = os.path.join(base_dir, "models", "classifier.pt")
    
    classifier = Classifier(512, 21) # ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶®‡ßã‡¶ü‡¶¨‡ßÅ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡ß®‡ßß‡¶ü‡¶ø ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏
    
    if os.path.exists(classifier_path):
        # weights_only=False ‡¶¶‡¶ø‡ßü‡ßá ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá ‡¶ï‡¶æ‡¶∞‡¶£ ‡¶Ü‡¶™‡¶®‡¶ø ‡¶™‡ßÅ‡¶∞‡ßã ‡¶Ö‡¶¨‡¶ú‡ßá‡¶ï‡ßç‡¶ü ‡¶∏‡ßá‡¶≠ ‡¶ï‡¶∞‡ßá‡¶õ‡ßá‡¶®
        checkpoint = torch.load(classifier_path, map_location=device, weights_only=False)
        if isinstance(checkpoint, dict):
            classifier.load_state_dict(checkpoint)
        else:
            classifier = checkpoint
            
    encoder.eval()
    classifier.eval()
    return encoder, classifier

# ‡ß©. ‡¶á‡¶â‡¶ú‡¶æ‡¶∞ ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡¶´‡ßá‡¶∏
st.set_page_config(page_title="Fish AI Expert", layout="centered")
st.title("üêü Fish Species Classification (SimCLR)")

with st.spinner('AI Models loading... Please wait.'):
    encoder, classifier = load_full_system()

uploaded_file = st.file_uploader("Upload fish image", type=["jpg", "png", "jpeg"])

if uploaded_file:
    img = Image.open(uploaded_file).convert("RGB")
    st.image(img, use_container_width=True)
    
    # ‡¶®‡ßã‡¶ü‡¶¨‡ßÅ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶ü‡ßç‡¶∞‡¶æ‡¶®‡ßç‡¶∏‡¶´‡¶∞‡ßç‡¶Æ
    preprocess = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    input_tensor = preprocess(img).unsqueeze(0)
    
    with torch.no_grad():
        feats = encoder(input_tensor)
        preds = classifier(feats)
        idx = torch.argmax(preds, 1).item()
    
    # ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶®‡ßã‡¶ü‡¶¨‡ßÅ‡¶ï‡ßá‡¶∞ ‡ß®‡ßß‡¶ü‡¶ø ‡¶Æ‡¶æ‡¶õ‡ßá‡¶∞ ‡¶®‡¶æ‡¶Æ
    CLASSES = ["Biam", "Bata", "Batasio(tenra)", "Chitul", "Croaker(Poya)", "Hilsha",
               "Kajoli", "Meni", "Pabda", "Poli", "Puti", "Rita", "Rui", "Rupchanda",
               "Silver Carp", "Telapiya", "carp", "Koi", "kaikka", "koral", "shrimp"]
    
    st.success(f"### Predicted Species: {CLASSES[idx]}")
