import streamlit as st
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image

# --- ‡ßß. ‡¶è‡¶®‡¶ï‡ßã‡¶°‡¶æ‡¶∞ (‡¶π‡ßÅ‡¶¨‡¶π‡ßÅ ‡¶®‡ßã‡¶ü‡¶¨‡ßÅ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ) ---
def get_encoder():
    encoder = models.resnet50(weights=None)
    encoder.fc = nn.Identity() 
    return encoder

# --- ‡ß®. ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡¶ø‡¶´‡¶æ‡ßü‡¶æ‡¶∞ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶∏‡¶¨‡¶ö‡¶æ‡¶á‡¶§‡ßá ‡¶®‡¶ø‡¶∞‡¶æ‡¶™‡¶¶ ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø ---
@st.cache_resource
def load_full_model():
    device = torch.device("cpu")
    
    # Hugging Face URLs
    ENCODER_URL = "https://huggingface.co/riad300/fish-simclr-encoder/resolve/main/encoder_simclr.pt"
    CLASSIFIER_URL = "https://huggingface.co/riad300/fish-simclr-encoder/resolve/main/classifier.pt"
    
    # ‡¶è‡¶®‡¶ï‡ßã‡¶°‡¶æ‡¶∞ ‡¶≤‡ßã‡¶°
    encoder = get_encoder()
    e_state = torch.hub.load_state_dict_from_url(ENCODER_URL, map_location=device, check_hash=False)
    encoder.load_state_dict(e_state)
    
    # ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡¶ø‡¶´‡¶æ‡ßü‡¶æ‡¶∞ ‡¶≤‡ßã‡¶° - ‡¶®‡¶æ‡¶Æ‡ßá‡¶∞ ‡¶ù‡¶æ‡¶Æ‡ßá‡¶≤‡¶æ ‡¶è‡ßú‡¶æ‡¶§‡ßá ‡¶∏‡¶∞‡¶æ‡¶∏‡¶∞‡¶ø Linear ‡¶≤‡ßá‡ßü‡¶æ‡¶∞‡ßá‡¶∞ state_dict ‡¶π‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶°‡ßá‡¶≤ ‡¶ï‡¶∞‡¶æ
    classifier = nn.Linear(2048, 21)
    c_state = torch.hub.load_state_dict_from_url(CLASSIFIER_URL, map_location=device, check_hash=False)
    
    # ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶´‡¶æ‡¶á‡¶≤‡ßá 'fc.weight' ‡¶è‡¶∞ ‡¶¨‡¶¶‡¶≤‡ßá ‡¶∂‡ßÅ‡¶ß‡ßÅ 'weight' ‡¶•‡¶æ‡¶ï‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá, ‡¶§‡¶æ‡¶á ‡¶è‡¶á ‡¶ö‡ßá‡¶ï‡¶ü‡¶ø ‡¶ú‡¶∞‡ßÅ‡¶∞‡¶ø
    new_state_dict = {}
    for key, value in c_state.items():
        new_key = key.replace('fc.', '') # 'fc.weight' ‡¶ï‡ßá 'weight' ‡¶¨‡¶æ‡¶®‡¶æ‡¶®‡ßã ‡¶π‡¶ö‡ßç‡¶õ‡ßá
        new_state_dict[new_key] = value
        
    classifier.load_state_dict(new_state_dict)
    
    encoder.eval()
    classifier.eval()
    return encoder, classifier

# --- ‡ß©. ‡¶á‡¶â‡¶ú‡¶æ‡¶∞ ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡¶´‡ßá‡¶∏ ---
st.set_page_config(page_title="Fish AI Expert")
st.title("üêü Fish Species AI Classifier")

encoder, classifier = load_full_model()

# ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶®‡ßã‡¶ü‡¶¨‡ßÅ‡¶ï‡ßá‡¶∞ ‡ß®‡ßß‡¶ü‡¶ø ‡¶Æ‡¶æ‡¶õ‡ßá‡¶∞ ‡¶®‡¶æ‡¶Æ‡ßá‡¶∞ ‡¶≤‡¶ø‡¶∏‡ßç‡¶ü
CLASSES = [
    "Biam", "Bata", "Batasio(tenra)", "Chitul", "Croaker(Poya)", "Hilsha",
    "Kajoli", "Meni", "Pabda", "Poli", "Puti", "Rita", "Rui", "Rupchanda",
    "Silver Carp", "Telapiya", "carp", "Koi", "kaikka", "koral", "shrimp"
]

uploaded_file = st.file_uploader("‡¶Æ‡¶æ‡¶õ‡ßá‡¶∞ ‡¶õ‡¶¨‡¶ø ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®", type=["jpg", "jpeg", "png"])

if uploaded_file:
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, width=400)
    
    # ‡¶á‡¶Æ‡ßá‡¶ú ‡¶™‡ßç‡¶∞‡¶ø-‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏‡¶ø‡¶Ç (Normalization values are standard for ResNet)
    tf = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    with torch.no_grad():
        input_tensor = tf(image).unsqueeze(0)
        # ‡ßß. ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶æ
        features = encoder(input_tensor)
        # ‡ß®. ‡¶∏‡¶†‡¶ø‡¶ï ‡¶Æ‡¶æ‡¶õ ‡¶∂‡¶®‡¶æ‡¶ï‡ßç‡¶§ ‡¶ï‡¶∞‡¶æ
        outputs = classifier(features)
        probs = torch.softmax(outputs, dim=1)
        confidence, idx = torch.max(probs, 1)
    
    # ‡¶∞‡ßá‡¶ú‡¶æ‡¶≤‡ßç‡¶ü ‡¶°‡¶ø‡¶∏‡¶™‡ßç‡¶≤‡ßá
    result_name = CLASSES[idx.item()]
    st.success(f"### ‡¶∞‡ßá‡¶ú‡¶æ‡¶≤‡ßç‡¶ü: {result_name}")
    st.write(f"‡¶ï‡¶®‡¶´‡¶ø‡¶°‡ßá‡¶®‡ßç‡¶∏: {confidence.item():.2%}")
