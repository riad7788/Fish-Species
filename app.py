import streamlit as st
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image

# рзз. ржкрзНрж░ржлрзЗрж╢ржирж╛рж▓ ржЖрж░рзНржХрж┐ржЯрзЗржХржЪрж╛рж░ рж╕рзЗржЯржЖржк (рзирззржЯрж┐ ржорж╛ржЫрзЗрж░ ржЬржирзНржп)
def get_model():
    # ResNet50 ржмрзЗрж╕ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ рж╣рзЯрзЗржЫрзЗ ржпрж╛ ржжрзЗрж╢рж┐ ржорж╛ржЫрзЗрж░ рж╕рзВржХрзНрж╖рзНржо ржкрж╛рж░рзНржержХрзНржп ржзрж░рждрзЗ ржкрж╛рж░рзЗ
    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
    num_ftrs = model.fc.in_features
    # ржЖржкржирж╛рж░ рзирззржЯрж┐ ржкрзНрж░ржЬрж╛рждрж┐рж░ рж▓рж┐рж╕рзНржЯ ржЕржирзБржпрж╛рзЯрзА ржЖржЙржЯржкрзБржЯ рж▓рзЗрзЯрж╛рж░
    model.fc = nn.Linear(num_ftrs, 21) 
    return model

# рзи. ржжрзЗрж╢рж┐ ржорж╛ржЫрзЗрж░ рж╕ржарж┐ржХ рждрж╛рж▓рж┐ржХрж╛
CLASSES = [
    "Baim (ржмрж╛ржЗржи)", "Bata (ржмрж╛ржЯрж╛)", "Batasio/Tengra (ржЯрзЗржВрж░рж╛)", "Chitul (ржЪрж┐рждрж▓)", 
    "Croaker/Poya (ржкрзЛржпрж╝рж╛)", "Hilsha (ржЗрж▓рж┐рж╢)", "Kajoli (ржХрж╛ржЬрж▓рзА)", "Meni (ржорзЗржирж┐)", 
    "Pabda (ржкрж╛ржмржжрж╛)", "Poli (ржлрж▓рж┐)", "Puti (ржкрзБржБржЯрж┐)", "Rita (рж░рж┐ржЯрж╛)", 
    "Rui (рж░рзБржЗ)", "Rupchanda (рж░рзВржкржЪрж╛ржБржжрж╛)", "Silver Carp (рж╕рж┐рж▓ржнрж╛рж░ ржХрж╛рж░рзНржк)", 
    "Telapiya (рждрзЗрж▓рж╛ржкрж┐рзЯрж╛)", "Carp (ржХрж╛рж░рзНржк)", "Koi (ржХрзИ)", 
    "Kaikka (ржХрж╛ржЗржХрзНржХрж╛)", "Koral (ржХрзЛрж░рж╛рж▓)", "Shrimp (ржЪрж┐ржВрзЬрж┐)"
]

st.set_page_config(page_title="BD Fish AI Expert", layout="centered")
st.title("ЁЯРЯ ржмрж╛ржВрж▓рж╛ржжрзЗрж╢рж┐ ржжрзЗрж╢рж┐ ржорж╛ржЫ рж╢ржирж╛ржХрзНрждржХрж╛рж░рзА AI")

# рзй. ржЙржирзНржиржд ржоржбрзЗрж▓ рж▓рзЛржбрж╛рж░
@st.cache_resource
def load_bd_expert():
    model = get_model()
    # ржПржЦрж╛ржирзЗ ржЖржкржирж╛рж░ ржпржжрж┐ ржЯрзНрж░рзЗржЗржи ржХрж░рж╛ .pt ржлрж╛ржЗрж▓ ржерж╛ржХрзЗ рждржмрзЗ рж╕рзЗржЯрж┐ рж▓рзЛржб рж╣ржмрзЗ
    model.eval()
    return model

model = load_bd_expert()
file = st.file_uploader("ржорж╛ржЫрзЗрж░ ржЫржмрж┐ ржЖржкрж▓рзЛржб ржХрж░рзБржи", type=["jpg", "png", "jpeg"])

if file:
    img = Image.open(file).convert("RGB")
    st.image(img, use_container_width=True)
    
    # рзк. ржЙржирзНржиржд ржЗржорзЗржЬ ржкрзНрж░рж╕рзЗрж╕рж┐ржВ (ржпрж╛рждрзЗ ржмрж╛ржЗржи ржорж╛ржЫрзЗрж░ ржорждрзЛ рж▓ржорзНржмрж╛ ржорж╛ржЫ ржнрж╛рж▓рзЛ ржЪрзЗржирзЗ)
    preprocess = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    
    input_tensor = preprocess(img).unsqueeze(0)
    
    with torch.no_grad():
        output = model(input_tensor)
        prob = torch.nn.functional.softmax(output[0], dim=0)
        conf, idx = torch.max(prob, 0)

    # рж░рзЗржЬрж╛рж▓рзНржЯ ржбрж┐рж╕ржкрзНрж▓рзЗ
    st.subheader("ЁЯФН рж╢ржирж╛ржХрзНрждржХрж░ржгрзЗрж░ ржлрж▓рж╛ржлрж▓:")
    
    result_name = CLASSES[idx.item()]
    
    # ржХржиржлрж┐ржбрзЗржирзНрж╕ рж▓рзЗржнрзЗрж▓ ржЕржирзБржпрж╛рзЯрзА ржорзЗрж╕рзЗржЬ
    if conf.item() > 0.45:
        st.success(f"### ржПржЯрж┐ рж╕ржорзНржнржмржд: **{result_name}**")
        st.info(f"ржирж┐рж╢рзНржЪрзЯрждрж╛: {conf.item()*100:.2f}%")
    else:
        # ржпржжрж┐ ржоржбрзЗрж▓ ржирж┐рж╢рзНржЪрж┐ржд ржирж╛ рж╣рзЯ
        st.warning("ржорж╛ржЫржЯрж┐ ржкрзБрж░рзЛржкрзБрж░рж┐ рж╕рзНржкрж╖рзНржЯ ржирзЯред ржЫржмрж┐ржЯрж┐рж░ ржорж╛ржЫржЯрж┐ ржЦрзБржм ржХрж╛ржЫрж╛ржХрж╛ржЫрж┐: **" + result_name + "**")
        st.write(f"ржоржбрзЗрж▓рзЗрж░ ржирж┐рж╢рзНржЪрзЯрждрж╛: {conf.item()*100:.2f}%")

st.divider()
st.info("ржЯрж┐ржкрж╕: ржорж╛ржЫрзЗрж░ ржкрзБрж░рзЛ рж╢рж░рзАрж░ ржПржмржВ ржЖржБржЗрж╢ ржпрзЗржи ржкрж░рж┐рж╖рзНржХрж╛рж░ ржжрзЗржЦрж╛ ржпрж╛рзЯ ржПржоржи ржЫржмрж┐ ржжрж┐ржиред")
