import streamlit as st
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import os

# --- ‡ßß. ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶Ü‡¶∞‡ßç‡¶ï‡¶ø‡¶ü‡ßá‡¶ï‡¶ö‡¶æ‡¶∞ (‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶®‡ßã‡¶ü‡¶¨‡ßÅ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ResNet50) ---
class SimCLR_Encoder(nn.Module):
    def __init__(self):
        super().__init__()
        # ‡¶®‡ßã‡¶ü‡¶¨‡ßÅ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ resnet50 ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü‡ßá‡¶õ‡ßá
        base_model = models.resnet50(weights=None)
        # ‡¶≤‡¶æ‡¶∏‡ßç‡¶ü ‡¶≤‡ßá‡ßü‡¶æ‡¶∞ ‡¶¨‡¶æ‡¶¶ ‡¶¶‡¶ø‡ßü‡ßá ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶è‡¶ï‡ßç‡¶∏‡¶ü‡ßç‡¶∞‡¶æ‡¶ï‡ßç‡¶ü‡¶∞ ‡¶§‡ßà‡¶∞‡¶ø
        self.encoder = nn.Sequential(*list(base_model.children())[:-1])

    def forward(self, x):
        h = self.encoder(x)
        return h.view(h.size(0), -1) # ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶°‡¶æ‡¶á‡¶Æ‡ßá‡¶®‡¶∂‡¶®: 2048

class Classifier(nn.Module):
    def __init__(self, in_dim, num_classes):
        super().__init__()
        self.fc = nn.Linear(in_dim, num_classes)

    def forward(self, x):
        return self.fc(x)

# --- ‡ß®. ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶≤‡ßã‡¶°‡¶ø‡¶Ç ‡¶´‡¶æ‡¶Ç‡¶∂‡¶® (Hugging Face + Local GitHub) ---
@st.cache_resource
def load_full_system():
    device = torch.device("cpu")
    
    # ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶è‡¶®‡¶ï‡ßã‡¶°‡¶æ‡¶∞ ‡¶≤‡¶ø‡¶ô‡ßç‡¶ï (Hugging Face)
    ENCODER_URL = "https://huggingface.co/riad300/fish-simclr-encoder/resolve/main/encoder_simclr.pt"
    
    # ‡¶è‡¶®‡¶ï‡ßã‡¶°‡¶æ‡¶∞ ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶° ‡¶ì ‡¶≤‡ßã‡¶°
    encoder = SimCLR_Encoder()
    try:
        # ‡¶∏‡¶∞‡¶æ‡¶∏‡¶∞‡¶ø ‡¶≤‡¶ø‡¶ô‡ßç‡¶ï ‡¶•‡ßá‡¶ï‡ßá ‡¶è‡¶®‡¶ï‡ßã‡¶°‡¶æ‡¶∞ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ
        state_dict = torch.hub.load_state_dict_from_url(ENCODER_URL, map_location=device)
        encoder.load_state_dict(state_dict)
    except Exception as e:
        st.error(f"Encoder loading error: {e}")

    # ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡¶ø‡¶´‡¶æ‡ßü‡¶æ‡¶∞ ‡¶≤‡ßã‡¶° (‡¶è‡¶ü‡¶ø GitHub ‡¶è‡¶∞ models/ ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶•‡ßá‡¶ï‡ßá ‡¶Ü‡¶∏‡¶¨‡ßá)
    base_dir = os.path.dirname(os.path.abspath(__file__))
    classifier_path = os.path.join(base_dir, "models", "classifier.pt")
    
    # ResNet50 ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶á‡¶®‡¶™‡ßÅ‡¶ü ‡ß®‡ß¶‡ß™‡ßÆ ‡¶è‡¶¨‡¶Ç ‡¶Æ‡¶æ‡¶õ ‡ß®‡ßß‡¶ü‡¶ø
    classifier = Classifier(2048, 21) 
    
    if os.path.exists(classifier_path):
        # ‡¶®‡ßã‡¶ü‡¶¨‡ßÅ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ
        c_state = torch.load(classifier_path, map_location=device, weights_only=False)
        if isinstance(c_state, dict):
            classifier.load_state_dict(c_state)
        else:
            classifier = c_state
    else:
        st.warning("Classifier weights not found! Please upload 'classifier.pt' to models/ folder.")
        
    encoder.eval()
    classifier.eval()
    return encoder, classifier

# --- ‡ß©. ‡¶á‡¶â‡¶ú‡¶æ‡¶∞ ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡¶´‡ßá‡¶∏ (Professional UI) ---
st.set_page_config(page_title="Fish AI Expert", page_icon="üêü", layout="centered")

st.markdown("<h1 style='text-align: center;'>üêü Fish Species AI Classifier</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center;'>Powered by SimCLR & ResNet50</p>", unsafe_allow_html=True)
st.write("---")

# ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ï‡¶≤ ‡¶ï‡¶∞‡¶æ
with st.spinner('AI Brain is loading...'):
    encoder, classifier = load_full_system()

# ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶®‡ßã‡¶ü‡¶¨‡ßÅ‡¶ï‡ßá‡¶∞ ‡ß®‡ßß‡¶ü‡¶ø ‡¶Æ‡¶æ‡¶õ‡ßá‡¶∞ ‡¶∏‡¶†‡¶ø‡¶ï ‡¶®‡¶æ‡¶Æ
CLASSES = [
    "Biam", "Bata", "Batasio(tenra)", "Chitul", "Croaker(Poya)", "Hilsha",
    "Kajoli", "Meni", "Pabda", "Poli", "Puti", "Rita", "Rui", "Rupchanda",
    "Silver Carp", "Telapiya", "carp", "Koi", "kaikka", "koral", "shrimp"
]

uploaded_file = st.file_uploader("üì§ ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶Æ‡¶æ‡¶õ‡ßá‡¶∞ ‡¶õ‡¶¨‡¶ø...", type=["jpg", "png", "jpeg"])

if uploaded_file:
    img = Image.open(uploaded_file).convert("RGB")
    
    # ‡¶∏‡ßÅ‡¶®‡ßç‡¶¶‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶°‡¶ø‡¶∏‡¶™‡ßç‡¶≤‡ßá ‡¶ï‡¶∞‡¶æ
    col1, col2 = st.columns([1, 1])
    with col1:
        st.image(img, caption="Uploaded Image", use_container_width=True)
    
    # ‡¶®‡ßã‡¶ü‡¶¨‡ßÅ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶á‡¶Æ‡ßá‡¶ú ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏‡¶ø‡¶Ç
    preprocess = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    input_tensor = preprocess(img).unsqueeze(0)
    
    with torch.no_grad():
        # ‡¶™‡ßç‡¶∞‡ßá‡¶°‡¶ø‡¶ï‡¶∂‡¶® ‡¶≤‡¶ú‡¶ø‡¶ï
        features = encoder(input_tensor)
        outputs = classifier(features)
        probs = torch.softmax(outputs, dim=1)
        confidence, idx = torch.max(probs, 1)
    
    with col2:
        st.subheader("üîç Prediction Results")
        st.success(f"**Species:** {CLASSES[idx.item()]}")
        st.info(f"**Confidence:** {confidence.item():.2%}")
        
        # ‡¶™‡ßç‡¶∞‡ßã‡¶ó‡ßç‡¶∞‡ßá‡¶∏ ‡¶¨‡¶æ‡¶∞ ‡¶¶‡¶ø‡ßü‡ßá ‡¶ï‡¶®‡¶´‡¶ø‡¶°‡ßá‡¶®‡ßç‡¶∏ ‡¶¶‡ßá‡¶ñ‡¶æ‡¶®‡ßã
        st.progress(confidence.item())

st.write("---")
st.caption("Developed by Riad | Capstone Project")
