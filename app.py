import streamlit as st
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image

# --- ‡ßß. ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶æ‡¶ï‡¶ö‡¶æ‡¶∞ (‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶®‡ßã‡¶ü‡¶¨‡ßÅ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ResNet50) ---
class SimCLR_Encoder(nn.Module):
    def __init__(self):
        super().__init__()
        # ResNet50 ‡¶¨‡ßá‡¶∏ ‡¶Æ‡¶°‡ßá‡¶≤
        base_model = models.resnet50(weights=None)
        self.encoder = nn.Sequential(*list(base_model.children())[:-1])

    def forward(self, x):
        h = self.encoder(x)
        return h.view(h.size(0), -1) # ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶°‡¶æ‡¶á‡¶Æ‡ßá‡¶®‡¶∂‡¶®: 2048

class Classifier(nn.Module):
    def __init__(self, in_dim=2048, num_classes=21):
        super().__init__()
        self.fc = nn.Linear(in_dim, num_classes)

    def forward(self, x):
        return self.fc(x)

# --- ‡ß®. ‡¶∏‡¶∞‡¶æ‡¶∏‡¶∞‡¶ø ‡¶≤‡¶ø‡¶ô‡ßç‡¶ï ‡¶•‡ßá‡¶ï‡ßá ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶≤‡ßã‡¶°‡¶ø‡¶Ç (Hugging Face) ---
@st.cache_resource
def load_full_model():
    device = torch.device("cpu")
    
    # ‡¶è‡¶®‡¶ï‡ßã‡¶°‡¶æ‡¶∞ ‡¶è‡¶¨‡¶Ç ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡¶ø‡¶´‡¶æ‡ßü‡¶æ‡¶∞ ‡¶á‡¶â‡¶Ü‡¶∞‡¶è‡¶≤
    ENCODER_URL = "https://huggingface.co/riad300/fish-simclr-encoder/resolve/main/encoder_simclr.pt"
    CLASSIFIER_URL = "https://huggingface.co/riad300/fish-simclr-encoder/resolve/main/classifier.pt"
    
    # ‡¶è‡¶®‡¶ï‡ßã‡¶°‡¶æ‡¶∞ ‡¶≤‡ßã‡¶°
    encoder = SimCLR_Encoder()
    e_state = torch.hub.load_state_dict_from_url(ENCODER_URL, map_location=device, check_hash=False)
    encoder.load_state_dict(e_state)
    
    # ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡¶ø‡¶´‡¶æ‡ßü‡¶æ‡¶∞ ‡¶≤‡ßã‡¶°
    classifier = Classifier()
    c_state = torch.hub.load_state_dict_from_url(CLASSIFIER_URL, map_location=device, check_hash=False)
    
    # ‡¶Ø‡ßá‡¶π‡ßá‡¶§‡ßÅ ‡¶Ü‡¶™‡¶®‡¶ø ‡¶®‡ßã‡¶ü‡¶¨‡ßÅ‡¶ï‡ßá ‡¶™‡ßÅ‡¶∞‡ßã ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶¨‡¶æ state_dict ‡¶Ø‡ßá‡¶ï‡ßã‡¶®‡ßã‡¶≠‡¶æ‡¶¨‡ßá ‡¶∏‡ßá‡¶≠ ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶®, ‡¶§‡¶æ‡¶á ‡¶è‡¶á ‡¶ö‡ßá‡¶ï‡¶ü‡¶ø ‡¶∞‡¶æ‡¶ñ‡¶æ ‡¶π‡ßü‡ßá‡¶õ‡ßá
    if isinstance(c_state, dict):
        classifier.load_state_dict(c_state)
    else:
        classifier = c_state
        
    encoder.eval()
    classifier.eval()
    return encoder, classifier

# --- ‡ß©. ‡¶á‡¶â‡¶ú‡¶æ‡¶∞ ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡¶´‡ßá‡¶∏ (UI) ---
st.set_page_config(page_title="Fish Species AI", page_icon="üêü")
st.title("üêü Fish Species AI Classifier")
st.markdown("‡ß®‡ßß‡¶ü‡¶ø ‡¶™‡ßç‡¶∞‡¶ú‡¶æ‡¶§‡¶ø‡¶∞ ‡¶Æ‡¶æ‡¶õ ‡¶∂‡¶®‡¶æ‡¶ï‡ßç‡¶§ ‡¶ï‡¶∞‡¶§‡ßá ‡¶õ‡¶¨‡¶ø ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®‡•§")

# ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ï‡¶≤ ‡¶ï‡¶∞‡¶æ
with st.spinner('‡¶Æ‡¶°‡ßá‡¶≤ ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶° ‡¶π‡¶ö‡ßç‡¶õ‡ßá... ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡¶¨‡¶æ‡¶∞ ‡¶ï‡¶ø‡¶õ‡ßÅ‡¶ï‡ßç‡¶∑‡¶£ ‡¶∏‡¶Æ‡ßü ‡¶®‡¶ø‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡•§'):
    encoder, classifier = load_full_model()

# ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶®‡ßã‡¶ü‡¶¨‡ßÅ‡¶ï‡ßá‡¶∞ ‡ß®‡ßß‡¶ü‡¶ø ‡¶Æ‡¶æ‡¶õ‡ßá‡¶∞ ‡¶®‡¶æ‡¶Æ
CLASSES = [
    "Biam", "Bata", "Batasio(tenra)", "Chitul", "Croaker(Poya)", "Hilsha",
    "Kajoli", "Meni", "Pabda", "Poli", "Puti", "Rita", "Rui", "Rupchanda",
    "Silver Carp", "Telapiya", "carp", "Koi", "kaikka", "koral", "shrimp"
]

uploaded_file = st.file_uploader("‡¶è‡¶ï‡¶ü‡¶ø ‡¶õ‡¶¨‡¶ø ‡¶∏‡¶ø‡¶≤‡ßá‡¶ï‡ßç‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®", type=["jpg", "jpeg", "png"])

if uploaded_file:
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="Uploaded Image", use_container_width=True)
    
    # ‡¶®‡ßã‡¶ü‡¶¨‡ßÅ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶á‡¶Æ‡ßá‡¶ú ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏‡¶ø‡¶Ç
    tf = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    input_tensor = tf(image).unsqueeze(0)
    
    with torch.no_grad():
        features = encoder(input_tensor)
        outputs = classifier(features)
        probs = torch.softmax(outputs, dim=1)
        confidence, idx = torch.max(probs, 1)
    
    st.success(f"### ‡¶∞‡ßá‡¶ú‡¶æ‡¶≤‡ßç‡¶ü: {CLASSES[idx.item()]}")
    st.info(f"‡¶ï‡¶®‡¶´‡¶ø‡¶°‡ßá‡¶®‡ßç‡¶∏: {confidence.item():.2%}")
