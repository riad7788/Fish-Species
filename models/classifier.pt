import torch
from torch import nn, optim
from torch.utils.data import DataLoader
from torchvision import transforms, datasets

# Encoder load & freeze
encoder = torch.load("encoder_simclr.pt", map_location="cpu")
encoder.eval()
for param in encoder.parameters():
    param.requires_grad = False

# Linear classifier
num_classes = 3
classifier = nn.Linear(2048, num_classes)

# Dataset
transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
])
train_dataset = datasets.ImageFolder("dataset/train", transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# Loss & optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(classifier.parameters(), lr=0.001)

# Training loop
for epoch in range(5):  # small example
    for images, labels in train_loader:
        with torch.no_grad():
            features = encoder(images)
        outputs = classifier(features)
        loss = criterion(outputs, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")

# Save classifier
torch.save(classifier, "classifier.pt")
print("âœ… Classifier trained and saved!")
